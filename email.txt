2016/09/28

The test has been done with PyTango 9 + ZMQ on SuSE Leap (single host); 
I used two emitter/receiver servers generating statistics for debugging.

I did the test sending bursts of events for periods of 5 seconds at increasing 
frequency (100 Hz, 200, 300, â€¦); the values sent are the expected timestamps 
for each value in an ideal world.

Defininig a "limit" for the event system in a motion control loop is a matter of 
deciding which delay is allowed between a hardware source and the client. The ValueDelay 
trend in the plot tries to quantify the amount of time (in milliseconds) passed since the 
HW generated the event and the client acknowledged (assuming buffering in the acquiring 
server and that the events are sent sequentially).

As you can see in the trends; soon after 300 events/second there's an increasing 
difference between the expected event frequency and the real one. In the code I'm 
compensating the threading waits to minimize the lost time; but still it's not able 
to keep up with frequencies > 500 Hz. I blame for the time waste in push_change_event 
that was found by Graziano Scalamera (see HDB++ meeting minutes); and maybe these 
numbers can be improved in C++.

See events-frequencies-T9.png

The light blue and pink lines show values are attributes from the Emitter 
(desired frequency vs achieved).
The dark blue and black lines show values are attributes from the Receiver. 
(received events and deviation from ideal).

As long as event buffers are big enough; I got no data lost.

It's pending to repeat the tests with notifd and other servers, suggestions are welcomed,
graphs with different versions of tango will be uploaded to github.


------------------------------------------------------------------------

REPORT DONE ON NOVEMBER 2015

Today we did some testing trying to define the maximum data throughput 
from notifd.

We found that there is a reproduceable limit between 1200 and 1700 
events/second. Once this point is reached we discover 2 types of error:

  - Client (Taurus) starts giving API_EventTimeout periodically (10s or 
30s); but the server continues pushing events at good rate.

  - Client hungs completely (continuous timeout traces) and the 
push_event starts to take very long to execute (~20ms for each push_event).

In both cases the timeout can be linked to a sudden peak in notifd cpu 
time followed by a fast increase in memory usage. In the second case the 
cpu usage of the notifd decreases again, but not the memory usage. The 
notifd cpu peak starts when the emmited events reach around 250000 since 
the start of the program; but this number may depend of many factors and 
not to be reproduceable.

Note that in both cases the client was NEVER able to receive more than 
1200 events/second; even when the client was not giving errors, every 
event sent by the server above this rate was lost. It means that there 
is a "grey zone" between 1200 and 1700 ev/sec where you are missing 
events and no error is raised.

As a comparison, with Tango8 we could reach 9000 events received by the 
client ... but not a higher number. As soon as the number of 
events/second reached 10000 we started getting "missed events" warnings 
(but not crashes nor memory leaks).

Attached a useless screenshot of the test,

Sergi & Dani

